{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用t_xsjbxxb中筛选得到的计算机学生名单，在t_cj_ben提取cs15-22的所有成绩，保存到t_cj_cs15-22\n",
    "```sql\n",
    "SELECT *\n",
    "FROM liwenhao.t_xsjbxxb\n",
    "WHERE bjmc ilike '%计算机%'\n",
    "\n",
    "SELECT *\n",
    "FROM liwenhao.t_cj_ben\n",
    "WHERE xh IN (SELECT xh FROM liwenhao.t_jsj_xsjbxxb);\n",
    "```\n",
    "简单预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('t_cj_cs15-22_origin.csv')\n",
    "\n",
    "# 剔除课程名中额外空格\n",
    "data['kcm'] = data['kcm'].str.strip()\n",
    "\n",
    "# 修改错误课程名\n",
    "data['kcm'] = data['kcm'].str.replace('高等数学I1', '高等数学I-1')\n",
    "data['kcm'] = data['kcm'].str.replace('高等数学I2', '高等数学I-2')\n",
    "data['kcm'] = data['kcm'].str.replace('线性代数与解析几何II', '线性代数与解析几何')\n",
    "data['kcm'] = data['kcm'].str.replace('金工实习Ⅰ', '金工实习')\n",
    "data['kcm'] = data['kcm'].str.replace('电工实习Ⅰ', '电工实习')\n",
    "data['kcm'] = data['kcm'].str.replace('电子技术实验-1', '电子技术实验1')\n",
    "data['kcm'] = data['kcm'].str.replace('电子技术实验-2', '电子技术实验2')\n",
    "data['kcm'] = data['kcm'].str.replace('大学物理I1', '大学物理I-1')\n",
    "data['kcm'] = data['kcm'].str.replace('大学物理I2', '大学物理I-2')\n",
    "data['kcm'] = data['kcm'].str.replace('大学物理II1', '大学物理II-1')\n",
    "data['kcm'] = data['kcm'].str.replace('大学物理II2', '大学物理II-2')\n",
    "data['kcm'] = data['kcm'].str.replace('大学物理实验I1', '大学物理实验I-1')\n",
    "data['kcm'] = data['kcm'].str.replace('大学物理实验I2', '大学物理实验I-2')\n",
    "data['kcm'] = data['kcm'].str.replace('工程制图III', '工程制图')\n",
    "\n",
    "# 剔除缺失值，去重\n",
    "data.dropna(subset=['zcj'], inplace=True)\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "# 保存修改后的数据集到新的CSV文件\n",
    "data.to_csv('t_cj_cs15-22.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "转化为学号-成绩表格，有多个成绩（补考）的取最高值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(by=['xh', 'zcj'], ascending=[\n",
    "                         True, False], inplace=True)\n",
    "data = data.groupby(['xh', 'kcm']).first().reset_index()\n",
    "\n",
    "# 透视表，将数据重新排列\n",
    "pivot_table = pd.pivot_table(data, values='zcj',\n",
    "                             index='xh', columns='kcm', aggfunc='sum', fill_value=0)\n",
    "\n",
    "# 保存结果到文件\n",
    "pivot_table.to_csv('cs15-22_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "筛选30%选课率以上的必修课程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# 读取CSV文件\n",
    "input_file = 'cs15-22_all.csv'\n",
    "output_file = 'cs15-22_compulsory.csv'\n",
    "\n",
    "# 定义阈值（30%）\n",
    "threshold = 30\n",
    "\n",
    "with open(input_file, 'r', newline='', encoding='utf-8') as infile, open(output_file, 'w', newline='', encoding='utf-8') as outfile:\n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile)\n",
    "\n",
    "    # 读取文件头\n",
    "    header = next(reader)\n",
    "    xh_index = header.index(\"xh\")  # 找到\"xh\"列的索引\n",
    "\n",
    "    # 初始化一个字典，用于统计每一列的零值数量和总行数\n",
    "    zero_counts = {}\n",
    "    total_rows = 0\n",
    "\n",
    "    # 统计每一列的零值数量\n",
    "    for col_index, col_name in enumerate(header):\n",
    "        if col_index != xh_index:\n",
    "            zero_counts[col_index] = 0\n",
    "\n",
    "    for row in reader:\n",
    "        total_rows += 1\n",
    "        for col_index, value in enumerate(row):\n",
    "            if col_index != xh_index and float(value) == 0.0:  # 排除\"xh\"列并检查是否为零\n",
    "                zero_counts[col_index] += 1\n",
    "\n",
    "    # 根据零值数量计算每一列的零值占比，决定是否保留\n",
    "    columns_to_keep = [header[xh_index]]  # 保留\"xh\"列的值\n",
    "    for col_index, zero_count in zero_counts.items():\n",
    "        zero_percentage = (zero_count / total_rows) * 100\n",
    "        if zero_percentage < 100 - threshold:\n",
    "            columns_to_keep.append(header[col_index])\n",
    "\n",
    "    # 重新写入文件头和符合条件的列\n",
    "    writer.writerow(columns_to_keep)\n",
    "\n",
    "    # 写入符合条件的行数据\n",
    "    infile.seek(0)  # 回到文件开头\n",
    "    next(reader)  # 跳过第一行\n",
    "    for row in reader:\n",
    "        row_to_write = [row[xh_index]]  # 保留\"xh\"列的值\n",
    "        for col_index, col_name in enumerate(header):\n",
    "            if col_index != xh_index and col_name in columns_to_keep:\n",
    "                row_to_write.append(row[col_index])\n",
    "        writer.writerow(row_to_write)\n",
    "\n",
    "print(\"处理完成，结果保存在 '{}' 文件中\".format(output_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "手动剔除体育类、政治类等课程，保存在cs15-22_main.csv中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正态性检验及处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import probplot, shapiro, kstest, anderson\n",
    "\n",
    "# 指定plt字体为宋体\n",
    "plt.rcParams['font.sans-serif'] = ['SimSun']\n",
    "\n",
    "data = pd.read_csv('cs15-22_main.csv')\n",
    "\n",
    "# 将零值替换为NaN，保存后再读取（不这样做会报错，推测和NULL值类型有关）\n",
    "data.replace(0, pd.NA, inplace=True)\n",
    "data.to_csv('cs15-22_main_NULL.csv', index=False)\n",
    "data = pd.read_csv('cs15-22_main_NULL.csv')\n",
    "# 获取数据集中的所有数值型变量列\n",
    "# numeric_columns = data.columns\n",
    "# numeric_columns = data.select_dtypes(include=['float', 'int'])\n",
    "\n",
    "non_normal = []\n",
    "\n",
    "for column_name in data.columns:\n",
    "    # 提取当前变量的数据列\n",
    "    column_data = data[column_name]\n",
    "    column_data = column_data.dropna()\n",
    "\n",
    "    # ------------ 执行Shapiro-Wilk正态性检验 --------------#\n",
    "    statistic, p_value = shapiro(column_data)\n",
    "\n",
    "    # # 输出检验统计量和p-value\n",
    "    # print(f'{column_name}:')\n",
    "    # print('  Shapiro-Wilk统计量：', statistic)\n",
    "    # print('  p-value：', p_value)\n",
    "\n",
    "    # # 输出检验结果\n",
    "    # if statistic < 0.9:\n",
    "    #     print(\"  不符合正态分布\")\n",
    "    # else:\n",
    "    #     print(\"  符合正态分布\")\n",
    "    \n",
    "    #------------ 生成 Q-Q 图 --------------#\n",
    "    # qq_plot = probplot(column_data, dist=\"norm\", plot=plt)\n",
    "    # # plt.plot(qq_plot[0], qq_plot[0], color='red', linestyle='--')\n",
    "    # plt.title(f\"{column_name}的Q-Q图\")\n",
    "    # plt.show()\n",
    "\n",
    "    # ------------ 执行Kolmogorov-Smirnov正态性检验 --------------#\n",
    "    ks_statistic, p_value = kstest(column_data, 'norm')\n",
    "\n",
    "    # 输出检验统计量和p-value\n",
    "    # print(f'{column_name}:')\n",
    "    # print('  Kolmogorov-Smirnov统计量：', statistic)\n",
    "    # print('  p-value：', p_value)\n",
    "\n",
    "    # 输出检验结果\n",
    "    if statistic < 0.9:\n",
    "        # print(\"  不符合正态分布\")\n",
    "        non_normal.append(column_name)\n",
    "    # else:\n",
    "        # print(\"  符合正态分布\")\n",
    "\n",
    "    # # ------------ Anderson-Darling检验 --------------#\n",
    "    # # 进行正态性评估\n",
    "    # result = anderson(column_data, 'norm')\n",
    "\n",
    "    # # 输出检验统计量和p-value\n",
    "    # print(f'{column_name}:')\n",
    "    # print('  Anderson-Darling统计量：', statistic)\n",
    "    # print('  p-value：', p_value)\n",
    "\n",
    "    # # 输出检验结果\n",
    "    # if p-value < 0.05:\n",
    "    #     print(\"  不符合正态分布\")\n",
    "    # else:\n",
    "    #     print(\"  符合正态分布\")\n",
    "\n",
    "# print(\"不符合正态分布的课程有\", non_normal\n",
    "\n",
    "# data.fillna('0', inplace=True)\n",
    "data = data.astype(float)\n",
    "\n",
    "## 筛选符合高斯分布的连续型变量\n",
    "# data.drop(columns=non_normal, inplace=True)\n",
    "# data.to_csv('cs15-22_continuous.csv',index=False)\n",
    "\n",
    "# # 筛选不符合高斯分布的变量，准备将其离散化·\n",
    "data = data.filter(items=non_normal)\n",
    "data.to_csv('cs15-22_discrete.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```r\n",
    "# 离散化为5类\n",
    "library(bnlearn)\n",
    "data <- read.csv(\"cs15-22_discrete.csv\")\n",
    "discretized_data <- discretize(data, method = \"interval\", breaks = 5)\n",
    "write.csv(discretized_data, file = \"cs15-22_discretized_data.csv\", row.names = FALSE)\n",
    "\n",
    "# 非超自然变换(npn)最大化高斯性\n",
    "library(huge)\n",
    "data <- read.csv(\"cs15-22_continuous.csv\")\n",
    "data_normalized <- huge.npn(data)\n",
    "write.csv(data_normalized, file = \"cs15-22_continuous_normalized.csv\", row.names = FALSE)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检验npn后的高斯性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import probplot, shapiro, kstest, anderson\n",
    "\n",
    "# 指定plt字体为宋体\n",
    "plt.rcParams['font.sans-serif'] = ['SimSun']\n",
    "data = pd.read_csv('cs15-22_continuous_normalized.csv')\n",
    "\n",
    "for column_name in data.columns:\n",
    "    # 提取当前变量的数据列\n",
    "    column_data = data[column_name]\n",
    "    column_data = column_data.dropna()\n",
    "\n",
    "    # ------------ 执行Shapiro-Wilk正态性检验 --------------#\n",
    "    # statistic, p_value = shapiro(column_data)\n",
    "\n",
    "    # # 输出检验统计量和p-value\n",
    "    # print(f'{column_name}:')\n",
    "    # print('  Shapiro-Wilk统计量：', statistic)\n",
    "    # print('  p-value：', p_value)\n",
    "    # # 输出检验结果\n",
    "    # if statistic < 0.9:\n",
    "    #     print(\"  不符合正态分布\")\n",
    "    # else:\n",
    "    #     print(\"  符合正态分布\")\n",
    "    \n",
    "    #------------ 生成 Q-Q 图 --------------#\n",
    "    qq_plot = probplot(column_data, dist=\"norm\", plot=plt)\n",
    "    plt.title(f\"{column_name}的Q-Q图\")\n",
    "    plt.show()\n",
    "\n",
    "    # ------------ 执行Kolmogorov-Smirnov正态性检验 --------------#\n",
    "    ks_statistic, p_value = kstest(column_data, 'norm')\n",
    "\n",
    "    #输出检验统计量和p-value\n",
    "    print(f'{column_name}:')\n",
    "    print('  Kolmogorov-Smirnov统计量：', ks_statistic)\n",
    "    print('  p-value：', p_value)\n",
    "    # 输出检验结果\n",
    "    if ks_statistic < 0.9:\n",
    "        print(\"  不符合正态分布\")\n",
    "        non_normal.append(column_name)\n",
    "    else:\n",
    "        print(\"  符合正态分布\")\n",
    "\n",
    "    # ------------ Anderson-Darling检验 --------------#\n",
    "    # # 进行正态性评估\n",
    "    # result = anderson(column_data, 'norm')\n",
    "\n",
    "    # # 输出检验统计量和p-value\n",
    "    # print(f'{column_name}:')\n",
    "    # print('  Anderson-Darling统计量：', result.statistic)\n",
    "    # print('  临界值：', result.critical_values)\n",
    "\n",
    "    # # 输出检验结果\n",
    "    # if result.statistic < result.critical_values[2]:\n",
    "    #     print(\"  不符合正态分布\")\n",
    "    # else:\n",
    "    #     print(\"  符合正态分布\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试npn数据的因果图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import cdt.causality.graph as graph\n",
    "import os\n",
    "\n",
    "data = pd.read_csv('cs15-22_discretized_data.csv')\n",
    "data.fillna('0', inplace=True)\n",
    "data.to_csv('cs15-22_discretized_data.csv', index=False)\n",
    "\n",
    "model = graph.PC(CItest=\"gaussian\",  alpha=0.05)\n",
    "output = model.predict(data)\n",
    "nx.drawing.nx_agraph.write_dot(output, 'cs15_22_PC.dot')\n",
    "os.system('dot -Tsvg cs15_22_PC.dot -o cs15_22_PC.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import cdt.causality.graph as graph\n",
    "import os\n",
    "\n",
    "data = pd.read_csv('cs15-22_continuous.csv')\n",
    "data = data.astype(float)\n",
    "model = graph.IAMB(alpha=0.05)\n",
    "output = model.predict(data)\n",
    "nx.drawing.nx_agraph.write_dot(output, 'cs15_22_IAMB.dot')\n",
    "os.system('dot -Tsvg cs15_22_IAMB.dot -o cs15_22_IAMB.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import cdt.causality.graph as graph\n",
    "import os\n",
    "\n",
    "data = pd.read_csv('cs15-22_continuous_normalized.csv')\n",
    "model = graph.IAMB()\n",
    "output = model.predict(data)\n",
    "nx.drawing.nx_agraph.write_dot(output, 'cs15_22_IAMB_normalized.dot')\n",
    "os.system('dot -Tsvg cs15_22_IAMB_normalized.dot -o cs15_22_IAMB_normalized.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "混合离散和npn数据"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
